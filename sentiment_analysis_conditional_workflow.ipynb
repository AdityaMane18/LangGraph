{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89dbd6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc7a32a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "513a0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model='gpt-4o-mini')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6ba0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "    sentiment: Literal[\"positive\", \"negative\"] = Field(description='Sentiment of the review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab3b665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description='The category of issue mentioned in the review')\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description='How urgent or critical the issue appears to be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6f85540",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(SentimentSchema)\n",
    "structured_model2 = model.with_structured_output(DiagnosisSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3048be08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'What is the sentiment of the following review - The software too bad'\n",
    "structured_model.invoke(prompt).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8bd6ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "    review: str\n",
    "    sentiment: Literal[\"positive\", \"negative\"]\n",
    "    diagnosis: dict\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b3ec1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: ReviewState):\n",
    "    prompt = f'For the following review find out the sentiment \\n {state[\"review\"]}'\n",
    "    sentiment = structured_model.invoke(prompt).sentiment\n",
    "    return {'sentiment' : sentiment}\n",
    "\n",
    "def check_sentiment(state: ReviewState) -> Literal[\"positive_response\", \"run_diagnosis\"]:\n",
    "    if state['sentiment'] == 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'\n",
    "\n",
    "def positive_response(state: ReviewState):\n",
    "    prompt = f\"\"\"Write a warm thank you message in response tot this review:\n",
    "    \\n\\n\\\"{state['review']}\\\"\\n\n",
    "    Also kindly ask the user to leave feedback on our website.\"\"\"\n",
    "\n",
    "    response = model.invoke(prompt).content\n",
    "    return {'response': response}\n",
    "\n",
    "def run_diagnosis(state: ReviewState):\n",
    "    prompt = f\"\"\"Diagnose this negative review:\\n\\n{state['review']}\\n\"\n",
    "    \"Return issue_type, tone and urgency.\"\"\"\n",
    "    response = structured_model2.invoke(prompt)\n",
    "    return {'diagnosis': response.model_dump()}\n",
    "\n",
    "def negative_response(state: ReviewState):\n",
    "    diagnosis = state['diagnosis']\n",
    "\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "Write an empathetic, helpful resolution message.\n",
    "\"\"\"\n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85d1a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ReviewState)\n",
    "graph.add_node('find_sentiment', find_sentiment)\n",
    "graph.add_node('positive_response', positive_response)\n",
    "graph.add_node('run_diagnosis', run_diagnosis)\n",
    "graph.add_node('negative_response', negative_response)\n",
    "graph.add_edge(START, 'find_sentiment')\n",
    "graph.add_conditional_edges('find_sentiment', check_sentiment)\n",
    "graph.add_edge('positive_response', END)\n",
    "graph.add_edge('run_diagnosis', 'negative_response')\n",
    "graph.add_edge('negative_response', END)\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46bcad96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'I’ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.',\n",
       " 'sentiment': 'negative',\n",
       " 'diagnosis': {'issue_type': 'Bug', 'tone': 'frustrated', 'urgency': 'high'},\n",
       " 'response': \"Subject: We're Here to Help with Your Bug Issue\\n\\nHi [User's Name],\\n\\nI hope this message finds you well. I understand that you’re facing a frustrating bug issue, and I want to assure you that I’m here to help you resolve it as quickly as possible.\\n\\nCould you please provide me with a bit more detail about the issue you’re experiencing? This will allow me to better assist you and find a solution that addresses your specific concerns. Any information about error messages, the steps leading up to the bug, or screenshots would be incredibly helpful.\\n\\nI appreciate your patience as we work through this together. Your experience is important to us, and I’ll do everything I can to get this resolved for you promptly.\\n\\nLooking forward to your reply!\\n\\nBest regards,  \\n[Your Name]  \\n[Your Position]  \\n[Your Contact Information]\"}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {\n",
    "    'review': 'I’ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.'\n",
    "}\n",
    "workflow.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
